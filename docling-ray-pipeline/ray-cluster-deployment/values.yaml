image:
  repository: quay.io/modh/ray
  tag: 2.35.0-py311-rocm62
  pullPolicy: IfNotPresent

nameOverride: "raycluster-docling"
fullnameOverride: ""

head:
  # rayVersion determines the autoscaler's image version.
  # It should match the Ray version in the image of the containers.
  rayVersion: 2.35.0
  enableInTreeAutoscaling: true
  autoscalerOptions:
    idleTimeoutSeconds: 240
  restartPolicy: ""
  lifecycle: #https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#pod-and-container-lifecyle-prestophook
    preStop:
      exec:
        command: [ "/bin/sh","-c","ray stop" ]
  rayStartParams:
    dashboard-host: '0.0.0.0'
    num-cpus: "0"
    block: 'true'
  # ports optionally allows specifying ports for the Ray container.
  ports:
    - containerPort: 6379
      name: gcs
    - containerPort: 8265
      name: dashboard
    - containerPort: 10001
      name: client
  # resource requests and limits for the Ray head container.
  # Modify as needed for your application.
  # Note that the resources in this example are much too small for production;
  # we don't recommend allocating less than 8G memory for a Ray pod in production.
  # Ray pods should be sized to take up entire K8s nodes when possible.
  # Always set CPU and memory limits for Ray pods.
  # It is usually best to set requests equal to limits.
  # See https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#resources
  # for further guidance.
  resources:
    limits:
      cpu: "1"
      # To avoid out-of-memory issues, never allocate less than 2G memory for the Ray head.
      memory: "8G"
    requests:
      cpu: "1"
      memory: "8G"
  volumes:
    - name: log-volume
      emptyDir: {}
  volumeMounts:
    - mountPath: /tmp/ray
      name: log-volume

worker:
  groupName: workergroup
  replicas: 0
  minReplicas: 0
  maxReplicas: 4
  rayStartParams:
    block: 'true'
    num-gpus: '0'
  containerEnv:
    - name: OMP_NUM_THREADS
      value: "1"
    - name: OPENBLAS_NUM_THREADS
      value: "1"
    - name: RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING
      value: "1"
  lifecycle: #https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#pod-and-container-lifecyle-prestophook
    preStop:
      exec:
        command: [ "/bin/sh","-c","ray stop" ]

  # resource requests and limits for the Ray head container.
  # Modify as needed for your application.
  # Note that the resources in this example are much too small for production;
  # we don't recommend allocating less than 8G memory for a Ray pod in production.
  # Ray pods should be sized to take up entire K8s nodes when possible.
  # Always set CPU and memory limits for Ray pods.
  # It is usually best to set requests equal to limits.
  # See https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#resources
  # for further guidance.
  resources:
    limits:
      cpu: "1"
      memory: "8G"
      #nvidia.com/gpu: 1
    requests:
      cpu: "1"
      memory: "8G"
      #nvidia.com/gpu: 1
  # Optional: The following volumes/volumeMounts configurations are optional but recommended because
  # Ray writes logs to /tmp/ray/session_latests/logs instead of stdout/stderr.
  volumes:
    - name: log-volume
      emptyDir: {}
  volumeMounts:
    - mountPath: /tmp/ray
      name: log-volume

# Configuration for Head's Kubernetes Service
service:
  # This is optional, and the default is ClusterIP.
  type: ClusterIP
